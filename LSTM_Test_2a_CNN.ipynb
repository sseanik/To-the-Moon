{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Test_2a_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhW8wOH4eEUT"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrEyrVxrgP7n"
      },
      "source": [
        "class JSONLoader:\n",
        "    @staticmethod\n",
        "    def save_json(company_name, data, label=\"\"):\n",
        "        filename = f'./demo/{company_name}_{label}.json' if label \\\n",
        "            else f'./demo/{company_name}.json'\n",
        "        with open(filename, 'w') as outfile:\n",
        "            json.dump(data, outfile)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_json(filename):\n",
        "        with open(filename, 'r') as infile:\n",
        "            data, metadata = json.load(infile)\n",
        "            return data, metadata\n",
        "\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpX_UCrKhOdH"
      },
      "source": [
        "ibm_data, ibm_metadata = JSONLoader.load_json(\"IBM_daily_adjusted.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m9za0kvhqa7"
      },
      "source": [
        "price_df = pd.DataFrame.from_dict(ibm_data, orient='index').astype('float')\n",
        "price_df = price_df.reindex(index=price_df.index[::-1])\n",
        "price_df.index = pd.to_datetime(price_df.index)\n",
        "price_df = price_df.asfreq(freq=\"B\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI4C4UXghyBN"
      },
      "source": [
        "train_cutoff = 4500\n",
        "training_set = price_df.iloc[:,4:5].values[:train_cutoff]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4XA4ecbm5UZ"
      },
      "source": [
        "# price_df\n",
        "training_set\n",
        "for i in np.where(np.isnan(training_set))[0]: \n",
        "  training_set[i] = training_set[i-1] if not np.isnan(training_set[i-1]) else 0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ_pgILcm5h8",
        "outputId": "61b12e27-7168-4a01-d4f2-2f314a93990b"
      },
      "source": [
        "training_set.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4500, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMn2pMv2hyFe"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_set_scaled = sc.fit_transform(training_set)\n",
        "# training_set_scaled = np.copy(training_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geX969WqmCr-",
        "outputId": "9aeeed82-2088-481f-f0e5-b925426546ee"
      },
      "source": [
        "np.max(training_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "159.577350449"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCQCgyGmj7If",
        "outputId": "b1a90642-d949-4564-f3bc-f6b4b2176244"
      },
      "source": [
        "# training_set_scaled[-30:]\n",
        "training_set_scaled[0:30]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.20571078],\n",
              "       [0.19592707],\n",
              "       [0.19370808],\n",
              "       [0.17953683],\n",
              "       [0.1729303 ],\n",
              "       [0.19214471],\n",
              "       [0.19052884],\n",
              "       [0.20759646],\n",
              "       [0.19749728],\n",
              "       [0.20189042],\n",
              "       [0.19275066],\n",
              "       [0.19557843],\n",
              "       [0.19118528],\n",
              "       [0.21264606],\n",
              "       [0.24264065],\n",
              "       [0.26248555],\n",
              "       [0.25334579],\n",
              "       [0.24546842],\n",
              "       [0.24546842],\n",
              "       [0.24799322],\n",
              "       [0.24390305],\n",
              "       [0.23819701],\n",
              "       [0.24001486],\n",
              "       [0.24935661],\n",
              "       [0.28268393],\n",
              "       [0.30353876],\n",
              "       [0.3066695 ],\n",
              "       [0.31505183],\n",
              "       [0.29025832],\n",
              "       [0.2681916 ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT6shCJ9kUzp"
      },
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "n_steps_in = 60\n",
        "for i in range(n_steps_in, train_cutoff):\n",
        "    X_train.append(training_set_scaled[i-n_steps_in:i, 0])\n",
        "    y_train.append(training_set_scaled[i, 0])\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbTgfxxJRT0F",
        "outputId": "86a3758f-c676-4ff0-dc9d-9d27807bf3cf"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.20571078, 0.19592707, 0.19370808, 0.17953683, 0.1729303 ,\n",
              "       0.19214471, 0.19052884, 0.20759646, 0.19749728, 0.20189042,\n",
              "       0.19275066, 0.19557843, 0.19118528, 0.21264606, 0.24264065,\n",
              "       0.26248555, 0.25334579, 0.24546842, 0.24546842, 0.24799322,\n",
              "       0.24390305, 0.23819701, 0.24001486, 0.24935661, 0.28268393,\n",
              "       0.30353876, 0.3066695 , 0.31505183, 0.29025832, 0.2681916 ,\n",
              "       0.27172631, 0.26945399, 0.25809241, 0.26915102, 0.27324119,\n",
              "       0.26920151, 0.27384714, 0.263142  , 0.26627275, 0.26627275,\n",
              "       0.27197879, 0.27228177, 0.2681916 , 0.2669292 , 0.26248555,\n",
              "       0.30353876, 0.28364335, 0.30353876, 0.29343957, 0.29091477,\n",
              "       0.31363794, 0.31868754, 0.32121234, 0.31490034, 0.32181829,\n",
              "       0.32181829, 0.30227636, 0.32121234, 0.31868754, 0.33131152])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGOddWZmls_y"
      },
      "source": [
        "n_features = 1\n",
        "n_seq = 2\n",
        "n_steps_cnn = int(n_steps_in/n_seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6GEv-57kvIl"
      },
      "source": [
        "# X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], n_features))\n",
        "X_train = X_train.reshape((X_train.shape[0], n_seq, n_steps_cnn, n_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMWq9VopmISy"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Conv1D\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.layers import Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bidGMjCQno_4"
      },
      "source": [
        "regressor = Sequential()\n",
        "\n",
        "# regressor.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features), return_sequences = True))\n",
        "\n",
        "regressor.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,n_steps_cnn,n_features)))\n",
        "regressor.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
        "regressor.add(TimeDistributed(Dropout(0.25)))\n",
        "regressor.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
        "regressor.add(TimeDistributed(Flatten()))\n",
        "regressor.add(LSTM(units = 100))\n",
        "regressor.add(Dropout(0.25))\n",
        "regressor.add(Dense(units = 100))\n",
        "regressor.add(Dense(units = 1))\n",
        "\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "id": "8FQ12ErBnpKj",
        "outputId": "4a607c15-a9f5-40b0-b09e-498e1deb197a"
      },
      "source": [
        "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "139/139 [==============================] - 5s 16ms/step - loss: 0.0197\n",
            "Epoch 2/100\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.0021\n",
            "Epoch 3/100\n",
            "139/139 [==============================] - 2s 15ms/step - loss: 0.0019\n",
            "Epoch 4/100\n",
            "139/139 [==============================] - 2s 15ms/step - loss: 0.0017\n",
            "Epoch 5/100\n",
            "139/139 [==============================] - 2s 15ms/step - loss: 0.0013\n",
            "Epoch 6/100\n",
            "139/139 [==============================] - 2s 15ms/step - loss: 0.0010\n",
            "Epoch 7/100\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 0.0010\n",
            "Epoch 8/100\n",
            "139/139 [==============================] - 2s 15ms/step - loss: 0.0011\n",
            "Epoch 9/100\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 7.9282e-04\n",
            "Epoch 10/100\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 9.1464e-04\n",
            "Epoch 11/100\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 8.7910e-04\n",
            "Epoch 12/100\n",
            "139/139 [==============================] - 2s 16ms/step - loss: 8.5938e-04\n",
            "Epoch 13/100\n",
            "105/139 [=====================>........] - ETA: 0s - loss: 7.8567e-04"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-18fefb168cfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3d7wjTXtGAA"
      },
      "source": [
        "# test_df = pd.read_csv('sample_data/tatatest.csv')\n",
        "test_set_size = 1000\n",
        "test_set = price_df.iloc[:,4:5].values[train_cutoff:train_cutoff+test_set_size]\n",
        "real_stock_price = test_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O97jyjF_fR85"
      },
      "source": [
        "for i in np.where(np.isnan(test_set))[0]: \n",
        "  test_set[i] = test_set[i-1] if not np.isnan(test_set[i-1]) else 0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxwu7uDJs_vo"
      },
      "source": [
        "dataset_total = price_df['5. adjusted close'].values[:train_cutoff+test_set_size]\n",
        "inputs = dataset_total[len(dataset_total)-len(test_set)-60:].reshape(-1,1)\n",
        "\n",
        "inputs = sc.transform(inputs)\n",
        "X_test = []\n",
        "for i in range(n_steps_in, n_steps_in+120):\n",
        "    X_test.append(inputs[i-n_steps_in:i, 0])\n",
        "X_test = np.array(X_test)\n",
        "# X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], n_seq, n_steps_cnn, n_features))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcfWEZkF2v6O"
      },
      "source": [
        "# X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], n_features))\n",
        "X_train = X_train.reshape((X_train.shape[0], n_seq, n_steps_cnn, n_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwvY389YVJik"
      },
      "source": [
        "X_samp = []\n",
        "train_end = training_set_scaled.shape[0]\n",
        "for i in range(train_end-n_steps_in, train_end-0):\n",
        "    X_samp.append(training_set_scaled[i-n_steps_in:i, 0])\n",
        "X_samp = np.array(X_samp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA56HsRqdY48"
      },
      "source": [
        "X_samp.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw-1xMcEcz4j"
      },
      "source": [
        "# X_samp = X_samp.reshape((X_samp.shape[0], X_samp.shape[1], 1))\n",
        "X_samp = X_samp.reshape(((X_samp.shape[0], n_seq, n_steps_cnn, n_features)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZEvI5YPvhOc"
      },
      "source": [
        "initial_data_o = price_df.iloc[:,4:5].values[:train_cutoff]\n",
        "initial_data = sc.transform(initial_data_o)\n",
        "# initial_data = np.copy(initial_data_o)\n",
        "test_data_o = price_df.iloc[:,4:5].values[train_cutoff:train_cutoff+120]\n",
        "test_data = sc.transform(test_data_o)\n",
        "# test_data = np.copy(test_data_o)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHZKwGnz6HPd"
      },
      "source": [
        "import pdb; \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3AqEaT9uO_4"
      },
      "source": [
        "def get_prediction(model, train, n_steps=60, max_intervals=120): \n",
        "  # pdb.set_trace()\n",
        "  predictions = []\n",
        "  x_data_i = train[-n_steps:].reshape((1, n_steps, train.shape[1]))\n",
        "  for i in range(max_intervals): \n",
        "    x_data = np.copy(x_data_i).reshape((1, n_seq, n_steps_cnn, n_features))\n",
        "    y_pred = model.predict(x_data)\n",
        "    predictions.append(y_pred)\n",
        "    x_data_i = np.hstack(( x_data_i[:,1:,:], y_pred.reshape((1, 1, 1)) ))\n",
        "  predictions = np.array(predictions)\n",
        "  predictions_c = np.concatenate(predictions)\n",
        "  return predictions_c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY3hr-vV787k"
      },
      "source": [
        "x_data = initial_data[-60:].reshape((1, n_seq, n_steps_cnn, n_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syrZSexm8rCf"
      },
      "source": [
        "x_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRkPI7SatGx3"
      },
      "source": [
        "predicted_stock_price = get_prediction(regressor, initial_data)\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)\n",
        "real_stock_price = np.copy(test_data)\n",
        "real_stock_price = sc.inverse_transform(real_stock_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHpIKGG-4Rrx"
      },
      "source": [
        "predicted_stock_price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9x9Wzaq2Bcg"
      },
      "source": [
        "predicted_last_2 = initial_data[-120:].reshape((120))\n",
        "X_data = []\n",
        "for i in range(60, 120):\n",
        "    X_data.append(predicted_last_2[i-60:i])\n",
        "X_data = np.array(X_data)\n",
        "# X_data = np.reshape(X_data, (X_data.shape[0], X_data.shape[1], 1))\n",
        "X_data = np.reshape(X_data, (X_data.shape[0], n_seq, n_steps_cnn, n_features))\n",
        "\n",
        "predicted_stock_price_2 = regressor.predict(X_data)\n",
        "predicted_stock_price_2 = sc.inverse_transform(predicted_stock_price_2)\n",
        "predicted_stock_price_2 = predicted_stock_price_2.reshape(-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BOVU3etcFWX"
      },
      "source": [
        "predicted_stock_price_3 = regressor.predict(X_test)\n",
        "predicted_stock_price_3 = sc.inverse_transform(predicted_stock_price_3)\n",
        "predicted_stock_price_3 = predicted_stock_price_3.reshape(-1)\n",
        "\n",
        "predicted_stock_price_4 = regressor.predict(X_samp)\n",
        "predicted_stock_price_4 = sc.inverse_transform(predicted_stock_price_4)\n",
        "predicted_stock_price_4 = predicted_stock_price_4.reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gGwfKPbtdQO"
      },
      "source": [
        "plt.figure(figsize = (18,9))\n",
        "\n",
        "pred_start = 60\n",
        "\n",
        "plt.plot(range(pred_start), initial_data_o[-60:], color='red', label='Actual prior')\n",
        "plt.plot(range(pred_start, pred_start+120), real_stock_price, color = 'orange', label = 'Actual')\n",
        "plt.plot(range(pred_start, pred_start+120), predicted_stock_price, color = 'blue', label = 'Predicted Walk Forward')\n",
        "plt.plot(range(pred_start, pred_start+60), predicted_stock_price_2, color = 'cyan', label = 'Predicted Block Previous')\n",
        "plt.plot(range(pred_start, pred_start+120), predicted_stock_price_3, color = 'green', label = 'Predicted')\n",
        "plt.plot(range(pred_start, pred_start+60), predicted_stock_price_4, color = 'magenta', label = 'Predicted Block Previous 2')\n",
        "plt.title('IBM Stock Price')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Price')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoBKYWTl4lzk"
      },
      "source": [
        "plt.figure(figsize=(18,9))\n",
        "\n",
        "plt.plot(initial_data_o)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvbvcpnY0Y1K"
      },
      "source": [
        "filename = \"./cnn_lstm.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH4FfvYWxvNb"
      },
      "source": [
        "regressor.save(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArtrRNVrp99C"
      },
      "source": [
        "from google.colab import files, drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDiLJN6Jqh7U"
      },
      "source": [
        "# files.download(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyu4rwC3qcVp"
      },
      "source": [
        "# drive.mount('./content/gdrive')\n",
        "# gdrive_path = f\"/content/gdrive/MyDrive/{filename}\"\n",
        "# print(gdrive_path)\n",
        "# s1 = model.save(filename)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}